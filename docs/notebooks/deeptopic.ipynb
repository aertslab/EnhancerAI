{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepTopic\n",
    "\n",
    "Sample notebook to train DeepTopic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enhancerai as enhai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use function {func}`enhancerai.import_topics` to import data into an {class}`anndata.AnnData` object,\n",
    "with the imported topics as the `AnnData.obs` and the consensus peak regions as the `AnnData.var`.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 3 × 23186\n",
       "    obs: 'file_path', 'n_open_regions'\n",
       "    var: 'n_topics', 'chr', 'start', 'end'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = enhai.import_topics(\n",
    "    topics_folder=\"../../tests/data/test_topics/\",\n",
    "    peaks_file=\"../../tests/data/test.peaks.bed\",\n",
    "    compress=True,\n",
    "    # topics_subset=[\"topic_1\", \"topic_2\"], # optional subset of topics to import\n",
    ")\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `import_topics` function will also add a couple of columns with variables of interest to your `AnnData.obs` and `Anndata.var` (AnnData.obs.n_open_regions and AnnData.var.n_topics), which you can use to inspect and get a feel of your data.\n",
    "\n",
    "To be able to do region to topic modelling, we'll need to add the DNA sequences to our `AnnData` object. We can do this by using {func}`enhancerai.pp.add_dna_sequence` and referencing to a local Fasta file with the `fasta_path=/path/to/local.fasta` argument. Alternatively, we can simple provide a name of a genome, which will use genomepy to download a reference genome. The DNA sequences will be located in your AnnData.varm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna.kuleuven.be/u0166574/miniconda3/envs/enhancerai/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████| 20/20 [00:01<00:00, 13.90it/s]\n",
      "/home/luna.kuleuven.be/u0166574/Desktop/projects/EnhancerAI/src/enhancerai/pp/_basic.py:118: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  adata.varm[code_varm_key] = sequence_df.applymap(_dna_to_code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2104</th>\n",
       "      <th>2105</th>\n",
       "      <th>2106</th>\n",
       "      <th>2107</th>\n",
       "      <th>2108</th>\n",
       "      <th>2109</th>\n",
       "      <th>2110</th>\n",
       "      <th>2111</th>\n",
       "      <th>2112</th>\n",
       "      <th>2113</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:194208032-194208532</th>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:92202766-92203266</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:92298990-92299490</th>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3406052-3406552</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:183669567-183670067</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:10603665-10604165</th>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169798868-169799368</th>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:93282061-93282561</th>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:38730592-38731092</th>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:58032109-58032609</th>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>...</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23186 rows × 2114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0    1    2    3    4    5    6    7    8    9     \\\n",
       "region                                                                       \n",
       "chr1:194208032-194208532    C    A    C    A    C    G    T    C    C    A   \n",
       "chr1:92202766-92203266      G    A    A    A    T    T    A    T    A    T   \n",
       "chr1:92298990-92299490      C    G    T    A    G    A    A    A    G    G   \n",
       "chr1:3406052-3406552        G    A    C    C    C    A    T    G    A    A   \n",
       "chr1:183669567-183670067    G    C    C    A    T    C    A    G    G    G   \n",
       "...                       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "chrX:10603665-10604165      A    G    C    C    C    A    G    G    C    C   \n",
       "chrX:169798868-169799368    G    A    A    A    T    A    T    A    G    T   \n",
       "chrX:93282061-93282561      G    T    C    C    A    G    C    A    A    T   \n",
       "chrX:38730592-38731092      A    C    A    T    A    G    T    T    G    C   \n",
       "chrX:58032109-58032609      G    G    G    A    C    T    C    A    A    C   \n",
       "\n",
       "                          ... 2104 2105 2106 2107 2108 2109 2110 2111 2112  \\\n",
       "region                    ...                                                \n",
       "chr1:194208032-194208532  ...    A    A    T    G    C    A    G    C    T   \n",
       "chr1:92202766-92203266    ...    T    G    A    A    T    A    A    A    C   \n",
       "chr1:92298990-92299490    ...    C    A    G    C    A    G    C    A    C   \n",
       "chr1:3406052-3406552      ...    T    A    T    T    G    C    C    C    T   \n",
       "chr1:183669567-183670067  ...    T    T    T    A    A    A    G    A    C   \n",
       "...                       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "chrX:10603665-10604165    ...    C    A    G    C    T    A    T    G    T   \n",
       "chrX:169798868-169799368  ...    T    T    G    G    T    A    T    T    T   \n",
       "chrX:93282061-93282561    ...    C    A    C    C    T    C    C    T    C   \n",
       "chrX:38730592-38731092    ...    A    T    G    A    G    A    A    C    T   \n",
       "chrX:58032109-58032609    ...    T    T    T    G    C    C    A    A    C   \n",
       "\n",
       "                         2113  \n",
       "region                         \n",
       "chr1:194208032-194208532    A  \n",
       "chr1:92202766-92203266      A  \n",
       "chr1:92298990-92299490      C  \n",
       "chr1:3406052-3406552        G  \n",
       "chr1:183669567-183670067    A  \n",
       "...                       ...  \n",
       "chrX:10603665-10604165      A  \n",
       "chrX:169798868-169799368    T  \n",
       "chrX:93282061-93282561      C  \n",
       "chrX:38730592-38731092      A  \n",
       "chrX:58032109-58032609      A  \n",
       "\n",
       "[23186 rows x 2114 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install genomepy  # If you want to add the DNA sequences using genomepy\n",
    "enhai.pp.add_dna_sequence(adata, genome_name=\"mm10\", genome_dir=\"~/genomepy/\")\n",
    "adata.varm[\"dna_sequence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we'll need to add a *split* column to our dataset, which we can do using {func}`enhancerai.pp.train_val_test`.  \n",
    "We can add a `random_state` to ensure the data will be split in the same manner in the future when `shuffle=True`(default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n",
      "train    18289\n",
      "test      3104\n",
      "val       1793\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_topics</th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chr1:194208032-194208532</th>\n",
       "      <td>1</td>\n",
       "      <td>chr1</td>\n",
       "      <td>194208032</td>\n",
       "      <td>194208532</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:92202766-92203266</th>\n",
       "      <td>1</td>\n",
       "      <td>chr1</td>\n",
       "      <td>92202766</td>\n",
       "      <td>92203266</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:92298990-92299490</th>\n",
       "      <td>1</td>\n",
       "      <td>chr1</td>\n",
       "      <td>92298990</td>\n",
       "      <td>92299490</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:3406052-3406552</th>\n",
       "      <td>1</td>\n",
       "      <td>chr1</td>\n",
       "      <td>3406052</td>\n",
       "      <td>3406552</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chr1:183669567-183670067</th>\n",
       "      <td>1</td>\n",
       "      <td>chr1</td>\n",
       "      <td>183669567</td>\n",
       "      <td>183670067</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:10603665-10604165</th>\n",
       "      <td>1</td>\n",
       "      <td>chrX</td>\n",
       "      <td>10603665</td>\n",
       "      <td>10604165</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:169798868-169799368</th>\n",
       "      <td>1</td>\n",
       "      <td>chrX</td>\n",
       "      <td>169798868</td>\n",
       "      <td>169799368</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:93282061-93282561</th>\n",
       "      <td>1</td>\n",
       "      <td>chrX</td>\n",
       "      <td>93282061</td>\n",
       "      <td>93282561</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:38730592-38731092</th>\n",
       "      <td>1</td>\n",
       "      <td>chrX</td>\n",
       "      <td>38730592</td>\n",
       "      <td>38731092</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chrX:58032109-58032609</th>\n",
       "      <td>1</td>\n",
       "      <td>chrX</td>\n",
       "      <td>58032109</td>\n",
       "      <td>58032609</td>\n",
       "      <td>val</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23186 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n_topics   chr      start        end  split\n",
       "region                                                               \n",
       "chr1:194208032-194208532         1  chr1  194208032  194208532  train\n",
       "chr1:92202766-92203266           1  chr1   92202766   92203266  train\n",
       "chr1:92298990-92299490           1  chr1   92298990   92299490  train\n",
       "chr1:3406052-3406552             1  chr1    3406052    3406552  train\n",
       "chr1:183669567-183670067         1  chr1  183669567  183670067  train\n",
       "...                            ...   ...        ...        ...    ...\n",
       "chrX:10603665-10604165           1  chrX   10603665   10604165    val\n",
       "chrX:169798868-169799368         1  chrX  169798868  169799368    val\n",
       "chrX:93282061-93282561           1  chrX   93282061   93282561    val\n",
       "chrX:38730592-38731092           1  chrX   38730592   38731092    val\n",
       "chrX:58032109-58032609           1  chrX   58032109   58032609    val\n",
       "\n",
       "[23186 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can split randomly on the regions\n",
    "enhai.pp.train_val_test_split(\n",
    "    adata, type=\"random\", val_size=0.1, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "# Or, choose the chromosomes for the validation and test sets\n",
    "enhai.pp.train_val_test_split(\n",
    "    adata, type=\"chr\", chr_val=[\"chr4\", \"chrX\"], chr_test=[\"chr2\", \"chr3\"]\n",
    ")\n",
    "\n",
    "print(adata.var[\"split\"].value_counts())\n",
    "adata.var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna.kuleuven.be/u0166574/miniconda3/envs/enhancerai/lib/python3.11/site-packages/torch/nn/modules/conv.py:306: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1040.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "from enhancerai.tl.zoo import DeepTopicCNN\n",
    "from enhancerai.tl.dataloaders import AnnDataModule\n",
    "from enhancerai.tl.tasks import DeepTopic\n",
    "\n",
    "# Chosen model architecture\n",
    "architecture = DeepTopicCNN(num_classes=3, seq_len=2114)\n",
    "\n",
    "# Datamodule, containing the train, validation and test dataloaders\n",
    "datamodule = AnnDataModule(adata, batch_size=32, num_workers=4, in_memory=False)\n",
    "\n",
    "# Task definition (losses, metrics, and how a training step is performed)\n",
    "task = DeepTopic(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlukas-mahieu\u001b[0m (\u001b[33mlukas-mahieu-vib\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240326_153250-uxi7ewdq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lukas-mahieu-vib/test/runs/uxi7ewdq' target=\"_blank\">test</a></strong> to <a href='https://wandb.ai/lukas-mahieu-vib/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lukas-mahieu-vib/test' target=\"_blank\">https://wandb.ai/lukas-mahieu-vib/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lukas-mahieu-vib/test/runs/uxi7ewdq' target=\"_blank\">https://wandb.ai/lukas-mahieu-vib/test/runs/uxi7ewdq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    }
   ],
   "source": [
    "from enhancerai.tl import Trainer\n",
    "\n",
    "# Define the Trainer object with run information\n",
    "trainer = Trainer(\n",
    "    max_epochs=5, project_name=\"test\", logger_type=\"wandb\", experiment_name=\"test\"\n",
    ")\n",
    "\n",
    "trainer.setup(architecture, task, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/luna.kuleuven.be/u0166574/miniconda3/envs/enhancerai/lib/python3.11/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:652: Checkpoint directory /home/luna.kuleuven.be/u0166574/Desktop/projects/EnhancerAI/docs/notebooks/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | loss          | BCELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | test_metrics  | MetricCollection | 0     \n",
      "4 | model         | DeepTopicCNN     | 15.3 M\n",
      "---------------------------------------------------\n",
      "15.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.3 M    Total params\n",
      "61.145    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 572/572 [01:03<00:00,  9.01it/s, v_num=ewdq, train/loss_step=0.476, val/loss=0.507, train/loss_epoch=0.565]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved. New best score: 0.507\n",
      "Epoch 0, global step 572: 'val/loss' reached 0.50726 (best 0.50726), saving model to '/home/luna.kuleuven.be/u0166574/Desktop/projects/EnhancerAI/docs/notebooks/checkpoints/best_model-v20.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 572/572 [01:04<00:00,  8.91it/s, v_num=ewdq, train/loss_step=0.567, val/loss=0.354, train/loss_epoch=0.511]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val/loss improved by 0.153 >= min_delta = 0.0. New best score: 0.354\n",
      "Epoch 1, global step 1144: 'val/loss' reached 0.35399 (best 0.35399), saving model to '/home/luna.kuleuven.be/u0166574/Desktop/projects/EnhancerAI/docs/notebooks/checkpoints/best_model-v20.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 572/572 [01:04<00:00,  8.89it/s, v_num=ewdq, train/loss_step=0.426, val/loss=0.427, train/loss_epoch=0.491]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 1716: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 572/572 [01:04<00:00,  8.88it/s, v_num=ewdq, train/loss_step=0.411, val/loss=0.463, train/loss_epoch=0.462]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 2288: 'val/loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 572/572 [01:04<00:00,  8.88it/s, v_num=ewdq, train/loss_step=0.520, val/loss=0.461, train/loss_epoch=0.428]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 2860: 'val/loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 572/572 [01:04<00:00,  8.88it/s, v_num=ewdq, train/loss_step=0.520, val/loss=0.461, train/loss_epoch=0.428]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luna.kuleuven.be/u0166574/miniconda3/envs/enhancerai/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 97/97 [00:03<00:00, 26.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/BinaryAUROC      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8045591115951538     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/BinaryAccuracy    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8115333318710327     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/BinaryF1Score     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6827412843704224     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/BinaryPrecision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.764035165309906     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/BinaryRecall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6223700046539307     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test/loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.43015256524086      </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/BinaryAUROC     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8045591115951538    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/BinaryAccuracy   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8115333318710327    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m   test/BinaryF1Score    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6827412843704224    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m  test/BinaryPrecision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.764035165309906    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m    test/BinaryRecall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6223700046539307    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test/loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.43015256524086     \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 725/725 [00:25<00:00, 28.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.1067867 , 0.0046143 , 0.9341833 ],\n",
       "       [0.02028829, 0.00234517, 0.98707086],\n",
       "       [0.1434106 , 0.01306714, 0.910435  ],\n",
       "       ...,\n",
       "       [0.41960293, 0.1983275 , 0.5014036 ],\n",
       "       [0.5516143 , 0.31703016, 0.14370385],\n",
       "       [0.43084353, 0.36422807, 0.2906354 ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "results = trainer.predict()\n",
    "\n",
    "# Reshape list of tensors to a numpy array\n",
    "results = np.vstack([x.cpu().numpy() for x in results])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sweep hyperparameters\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"val_loss\", \"goal\": \"minimize\"},\n",
    "    \"max_trials\": 10,\n",
    "    \"parameters\": {\n",
    "        \"architecture\": {\n",
    "            \"architecture\": \"DeepTopicCNN\",\n",
    "            \"num_classes\": 3,\n",
    "            \"seq_len\": 2114,\n",
    "            \"num_filters\": {\"values\": [256, 512, 1024]},\n",
    "            \"kernel_size\": {\"values\": [3, 5, 7]},\n",
    "        },\n",
    "        \"datamodule\": {\n",
    "            \"batch_size\": {\"values\": [16, 32, 64]},\n",
    "        },\n",
    "        \"task\": {\n",
    "            \"lr\": {\"min\": 1e-5, \"max\": 1e-3},\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=5, project_name=\"test\", logger=\"wandb\", experiment_name=\"test\"\n",
    ")\n",
    "\n",
    "trainer.sweep(architecture, datamodule, task, sweep_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enhancerai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
